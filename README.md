# toxic-comments-classifier
Toxic comments classifier is a simple machine learning project which is used to classify inappropriate comments and sort them out into their corresponding toxic labels like an obscene, threat, insult, etc. The work is depicted using a normal end-to-end chat application that runs a pre-trained ML model in the backend. The training model uses supervised learning along with logistic regression.
